# Gu√≠a de Configuraci√≥n de Base de Datos - Document Analyzer

## üìã Overview

Esta gu√≠a te ayudar√° a configurar completamente la base de datos de Supabase para Document Analyzer. El sistema incluye 15 tablas optimizadas con seguridad, auditor√≠a y m√©tricas de rendimiento.

## üöÄ Configuraci√≥n Autom√°tica (Recomendada)

Ya ejecutaste el script de configuraci√≥n autom√°tica que instal√≥ todas las dependencias necesarias. Ahora solo necesitas ejecutar el schema SQL manualmente en Supabase.

## üóÑÔ∏è Paso 1: Ejecutar Schema SQL en Supabase

### 1.1 Accede al Dashboard de Supabase
```
üìÇ URL: https://supabase.com/dashboard/project/zolffzfbxkgiozfbbjnm
```

### 1.2 Abre el SQL Editor
1. En el men√∫ lateral, haz clic en **"SQL Editor"**
2. Haz clic en **"New query"** para crear una nueva consulta

### 1.3 Copia y Pega el Schema
1. Abre el archivo: `database/supabase-schema.sql`
2. Copia todo el contenido (598 l√≠neas)
3. P√©galo en el SQL Editor

### 1.4 Ejecuta el Schema
1. Haz clic en **"Run"** o presiona `Ctrl+Enter`
2. Espera a que se completen todas las operaciones
3. Verifica que no haya errores en la consola

## üìä Estructura de Base de Datos Creada

### üë• Tablas de Usuarios
- **`profiles`** - Perfiles extendidos con roles y suscripciones
- **`user_api_configs`** - Configuraciones encriptadas de APIs

### üìÑ Tablas de Documentos
- **`documents`** - Metadatos y almacenamiento de archivos
- **`document_analyses`** - An√°lisis realizados a documentos
- **`analysis_results_basic`** - Resultados b√°sicos de an√°lisis
- **`analysis_results_advanced`** - Resultados avanzados
- **`analysis_results_ai`** - Resultados de an√°lisis con IA

### üîç Tablas de OCR
- **`ocr_processes`** - Procesamientos OCR con seguimiento
- **`ocr_results`** - Resultados detallados por p√°gina
- **`document_conversions`** - Conversiones a diferentes formatos

### ü§ñ Tablas de IA
- **`ai_model_metrics`** - Registro de uso y rendimiento de modelos
- **`model_optimization_history`** - Historial de optimizaciones
- **`usage_statistics`** - Estad√≠sticas agregadas por usuario

### üì¶ Tablas de Batch Processing
- **`batch_jobs`** - Trabajos por lotes con seguimiento
- **`batch_job_files`** - Archivos individuales en lotes

### üîç Tablas de Auditor√≠a
- **`audit_logs`** - Registro completo de auditor√≠a
- **`error_logs`** - Logs de errores del sistema
- **`system_settings`** - Configuraciones del sistema

## üîê Caracter√≠sticas de Seguridad

### Row Level Security (RLS)
- Todas las tablas tienen pol√≠ticas RLS implementadas
- Los usuarios solo pueden acceder a sus propios datos
- Validaci√≥n autom√°tica de permisos

### Encriptaci√≥n
- API keys almacenadas con encriptaci√≥n base64
- Datos sensibles protegidos
- Validaci√≥n de inputs en todos los endpoints

### Triggers Autom√°ticos
- Actualizaci√≥n autom√°tica de timestamps
- Creaci√≥n de perfiles al registrar usuarios
- Actualizaci√≥n de estad√≠sticas en tiempo real

## üéØ Vistas √ötiles Creadas

### `user_document_summary`
Resumen de documentos por usuario:
```sql
SELECT * FROM user_document_summary WHERE user_id = 'your_user_id';
```

### `user_ai_metrics_summary`
M√©tricas de IA agregadas:
```sql
SELECT * FROM user_ai_metrics_summary WHERE user_id = 'your_user_id';
```

### `system_status`
Estado general del sistema:
```sql
SELECT * FROM system_status;
```

## üìà √çndices Optimizados

### √çndices Compuestos
- Para consultas frecuentes de usuario + fecha
- Para b√∫squedas de documentos por estado
- Para m√©tricas de rendimiento por modelo

### √çndices GIN
- Para b√∫squeda de texto completo
- Para arrays de etiquetas y metadatos

### √çndices Temporales
- Para consultas por rangos de fecha
- Para auditor√≠a hist√≥rica

## üß™ Verificaci√≥n de Instalaci√≥n

### 1. Verificar Tablas Creadas
```sql
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public' 
ORDER BY table_name;
```

Deber√≠as ver 15 tablas principales + 3 vistas.

### 2. Verificar Pol√≠ticas RLS
```sql
SELECT schemaname, tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
AND rowsecurity = true;
```

### 3. Verificar Triggers
```sql
SELECT trigger_name, event_manipulation, event_object_table 
FROM information_schema.triggers 
WHERE trigger_schema = 'public';
```

## üîß Configuraci√≥n Adicional

### 1. Configurar API Keys de IA
Edita el archivo `.env.local`:
```bash
# Groq API (para an√°lisis de texto)
GROQ_API_KEY=your_groq_api_key_here

# Chutes API (para an√°lisis avanzado)
CHUTES_API_KEY=your_chutes_api_key_here

# OpenAI (opcional, para an√°lisis adicional)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (opcional, para an√°lisis adicional)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
```

### 2. Obtener API Keys

#### Groq API
1. Ve a: https://console.groq.com/
2. Reg√≠strate o inicia sesi√≥n
3. Ve a "API Keys"
4. Crea una nueva key y c√≥piala

#### Chutes API
1. Ve a: https://chutes.ai/
2. Reg√≠strate o inicia sesi√≥n
3. Ve a "Dashboard" > "API Settings"
4. Genera una nueva API key

## üöÄ Iniciar la Aplicaci√≥n

### 1. Iniciar el Servidor
```bash
npm start
```

### 2. Acceder a la Aplicaci√≥n
```
üåê URL: http://localhost:3000
```

### 3. Configurar APIs en la Interfaz
1. Haz clic en **"Configuraci√≥n de APIs"**
2. Ingresa tus API keys
3. Prueba la conexi√≥n
4. Guarda la configuraci√≥n

## üìä Monitoreo y M√©tricas

### M√©tricas Disponibles
- Tiempos de respuesta por modelo
- Costos de uso por API
- Precisi√≥n de an√°lisis
- Estad√≠sticas de uso por usuario

### Consultas √ötiles
```sql
-- M√©tricas de uso por modelo
SELECT model_name, AVG(response_time), AVG(cost_per_request)
FROM ai_model_metrics 
WHERE created_at >= NOW() - INTERVAL '7 days'
GROUP BY model_name;

-- Documentos procesados por d√≠a
SELECT DATE(uploaded_at) as date, COUNT(*) as documents
FROM documents
WHERE uploaded_at >= NOW() - INTERVAL '30 days'
GROUP BY DATE(uploaded_at)
ORDER BY date;
```

## üîç Soluci√≥n de Problemas

### Error: "column created_at does not exist"
**Causa:** El schema SQL tiene referencias incorrectas a columnas
**Soluci√≥n:**
1. Primero prueba con el schema m√≠nimo: `database/minimal-test-schema.sql`
2. Si el schema m√≠nimo funciona, el problema est√° en el schema completo
3. Verifica que todas las referencias a `documents.created_at` usen `documents.uploaded_at`

### Error: "invalid input syntax for type json"
**Causa:** Valores JSON incorrectamente formateados en los INSERT statements
**Soluci√≥n:**
1. Verifica que todos los valores JSON est√©n entre comillas dobles
2. Ejemplo incorrecto: `'spa+eng'`
3. Ejemplo correcto: `'"spa+eng"'`
4. Los strings en JSON deben estar entre comillas dobles

### Error: "Could not find the table"
**Causa:** El schema no se ejecut√≥ completamente
**Soluci√≥n:** Re-ejecuta el schema SQL completo

### Error: "Permission denied"
**Causa:** Las pol√≠ticas RLS no se aplicaron
**Soluci√≥n:** Verifica que las pol√≠ticas est√©n habilitadas

### Error: "Connection refused"
**Causa:** Configuraci√≥n incorrecta de Supabase
**Soluci√≥n:** Verifica URL y API keys en `.env.local`

### üß™ Prueba con Schema M√≠nimo

Si tienes problemas con el schema completo:

1. **Prueba primero el schema m√≠nimo:**
   ```sql
   -- Copia y pega el contenido de database/minimal-test-schema.sql
   ```

2. **Si funciona, el problema est√° en el schema completo**
   - Revisa las referencias a columnas
   - Verifica nombres de tablas
   - Ejecuta statement por statement

3. **Herramienta de diagn√≥stico:**
   ```bash
   node scripts/test-schema.js
   ```

## üìö Documentaci√≥n Adicional

- [Gu√≠a de Configuraci√≥n de IA](docs/ai-setup-guide.md)
- [Gu√≠a de OCR](docs/ocr-guide.md)
- [Referencia de Modelos](docs/models-reference.md)
- [Recomendaciones de Modelos](docs/ai-model-recommendations.md)

## üéâ ¬°Listo!

Una vez completados estos pasos, tu base de datos estar√° completamente configurada y lista para usar con Document Analyzer. El sistema ahora puede:

‚úÖ Almacenar y gestionar documentos  
‚úÖ Realizar an√°lisis con m√∫ltiples modelos de IA  
‚úÖ Procesar im√°genes con OCR  
‚úÖ Mantener historial completo de uso  
‚úÖ Proporcionar m√©tricas y estad√≠sticas  
‚úÖ Garantizar seguridad y privacidad  

¬°Disfruta de Document Analyzer con base de datos enterprise-ready!
# Referencia Completa de Modelos de IA

Esta guÃ­a describe todos los modelos de IA disponibles en Document Analyzer, sus caracterÃ­sticas y casos de uso recomendados.

## ğŸ¤– Modelos Groq

Groqæä¾›è¶…å¿«é€Ÿçš„AIæ¨ç†æœåŠ¡ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ç¡¬ä»¶æ ˆå®ç°æä½çš„å»¶è¿Ÿã€‚

### 1. Llama 3.1 8B Instant

**ID del Modelo**: `llama-3.1-8b-instant`

#### ğŸ“Š CaracterÃ­sticas TÃ©cnicas
- **ParÃ¡metros**: 8 mil millones
- **Ventana de Contexto**: 131,072 tokens
- **Velocidad**: âš¡âš¡âš¡âš¡âš¡ Ultra RÃ¡pida
- **Latencia**: < 100ms promedio
- **Costo**: $ mÃ¡s econÃ³mico

#### ğŸ¯ Casos de Uso Recomendados
- âœ… **AnÃ¡lisis rÃ¡pido de documentos simples**
- âœ… **ClasificaciÃ³n bÃ¡sica de contenido**
- âœ… **ResÃºmenes cortos y directos**
- âœ… **ExtracciÃ³n de entidades simple**
- âœ… **Procesamiento en tiempo real**

#### âš¡ Ventajas
- Respuestas casi instantÃ¡neas
- Bajo costo de procesamiento
- Ideal para aplicaciones interactivas
- Manejo eficiente de documentos pequeÃ±os

#### ğŸ”´ Limitaciones
- Menor profundidad de anÃ¡lisis
- Capacidades de razonamiento limitadas
- No ideal para contenido complejo

---

### 2. Llama 3.3 70B Versatile

**ID del Modelo**: `llama-3.3-70b-versatile`

#### ğŸ“Š CaracterÃ­sticas TÃ©cnicas
- **ParÃ¡metros**: 70 mil millones
- **Ventana de Contexto**: 131,072 tokens
- **Velocidad**: âš¡âš¡âš¡ Balanceada
- **Latencia**: 200-500ms promedio
- **Costo**: $$ econÃ³mico

#### ğŸ¯ Casos de Uso Recomendados
- âœ… **AnÃ¡lisis general de documentos**
- âœ… **ClasificaciÃ³n detallada**
- âœ… **ResÃºmenes de calidad media-alta**
- âœ… **AnÃ¡lisis de sentimiento preciso**
- âœ… **ExtracciÃ³n de insights bÃ¡sicos**
- âœ… **Documentos de longitud media**

#### âš¡ Ventajas
- Excelente relaciÃ³n calidad/velocidad
- Buen manejo de lenguaje complejo
- VersÃ¡til para mÃºltiples tipos de anÃ¡lisis
- Balance ideal para la mayorÃ­a de casos

#### ğŸ”´ Limitaciones
- MÃ¡s costoso que el modelo instantÃ¡neo
- Latencia mayor para documentos muy largos

---

### 3. Mixtral 8x7B

**ID del Modelo**: `mixtral-8x7b-32768`

#### ğŸ“Š CaracterÃ­sticas TÃ©cnicas
- **ParÃ¡metros**: 47 mil millones (8 expertos Ã— 7B)
- **Ventana de Contexto**: 32,768 tokens
- **Velocidad**: âš¡âš¡ Lenta pero precisa
- **Latencia**: 500-1000ms promedio
- **Costo**: $$$ premium

#### ğŸ¯ Casos de Uso Recomendados
- âœ… **AnÃ¡lisis profundo y detallado**
- âœ… **ResÃºmenes ejecutivos de alta calidad**
- âœ… **AnÃ¡lisis crÃ­tico complejo**
- âœ… **Razonamiento multi-paso**
- âœ… **Documentos largos y complejos**
- âœ… **Insights estratÃ©gicos**

#### âš¡ Ventajas
- MÃ¡xima calidad de anÃ¡lisis
- Excelentes capacidades de razonamiento
- Manejo superior de contenido complejo
- Ideal para anÃ¡lisis crÃ­tico

#### ğŸ”´ Limitaciones
- Mayor tiempo de procesamiento
- Costo mÃ¡s elevado
- Ventana de contexto mÃ¡s pequeÃ±a

---

## ğŸŒ Modelos Chutes.ai

Chutes.ai es una plataforma descentralizada que ofrece modelos especializados con aceleraciÃ³n GPU.

### CaracterÃ­sticas de la Plataforma

#### ğŸ—ï¸ Arquitectura
- **Red Descentralizada**: Basada en ecosistema Bittensor
- **AceleraciÃ³n GPU**: Procesamiento paralelo optimizado
- **Modelos Especializados**: Fine-tuned para dominios especÃ­ficos
- **Escalabilidad Horizontal**: MÃºltiples nodos de procesamiento

#### ğŸ¯ Especializaciones Disponibles
- **AnÃ¡lisis de Documentos**: Modelos optimizados para PDF/PPTX
- **ExtracciÃ³n de Entidades**: DetecciÃ³n precisa de informaciÃ³n estructurada
- **ClasificaciÃ³n de Contenido**: CategorizaciÃ³n automÃ¡tica avanzada
- **AnÃ¡lisis de Sentimiento**: DetecciÃ³n emocional contextual
- **Resumen AutomÃ¡tico**: GeneraciÃ³n condensada de contenido

#### âš¡ Ventajas de Chutes.ai
- Modelos especializados para documentos
- Procesamiento paralelo de alto rendimiento
- Capacidades de fine-tuning personalizadas
- Ecosistema descentralizado resistente

#### ğŸ”´ Consideraciones
- Requiere configuraciÃ³n de wallet Bittensor
- Disponibilidad variable segÃºn red
- Costos basados en mercado de subastas

---

## ğŸ“Š ComparaciÃ³n Detallada

### Tabla Comparativa

| Modelo | ParÃ¡metros | Contexto | Velocidad | Costo | Calidad | Uso Ideal |
|--------|------------|----------|----------|-------|--------|-----------|
| `llama-3.1-8b-instant` | 8B | 131K | âš¡âš¡âš¡âš¡âš¡ | $ | âš¡âš¡âš¡ | RÃ¡pido |
| `llama-3.3-70b-versatile` | 70B | 131K | âš¡âš¡âš¡ | $$ | âš¡âš¡âš¡âš¡âš¡ | General |
| `mixtral-8x7b-32768` | 47B | 32K | âš¡âš¡ | $$$ | âš¡âš¡âš¡âš¡âš¡ | Profundo |
| `chutes-specialized` | Variable | Variable | âš¡âš¡âš¡ | $$ | âš¡âš¡âš¡âš¡ | Especializado |

### MÃ©tricas de Rendimiento

#### ğŸ“ˆ Velocidad de Procesamiento
- **Llama 3.1 8B**: ~100ms para 1K tokens
- **Llama 3.3 70B**: ~300ms para 1K tokens
- **Mixtral 8x7B**: ~600ms para 1K tokens
- **Chutes.ai**: ~200-400ms (variable)

#### ğŸ’° Costo por 1M Tokens
- **Llama 3.1 8B**: ~$0.05-0.10
- **Llama 3.3 70B**: ~$0.20-0.50
- **Mixtral 8x7B**: ~$0.50-1.00
- **Chutes.ai**: ~$0.15-0.40 (variable)

#### ğŸ¯ PrecisiÃ³n de AnÃ¡lisis
- **Llama 3.1 8B**: 70-75% (tareas simples)
- **Llama 3.3 70B**: 85-90% (tareas generales)
- **Mixtral 8x7B**: 90-95% (tareas complejas)
- **Chutes.ai**: 80-90% (tareas especializadas)

---

## ğŸ›ï¸ ConfiguraciÃ³n y Uso

### SelecciÃ³n AutomÃ¡tica de Modelos

La aplicaciÃ³n selecciona automÃ¡ticamente el modelo Ã³ptimo basado en:

```javascript
// LÃ³gica de selecciÃ³n automÃ¡tica
function selectOptimalModel(documentSize, complexity, analysisType) {
    if (analysisType === 'fast' || documentSize < 1000) {
        return 'llama-3.1-8b-instant';
    } else if (analysisType === 'balanced' || documentSize < 5000) {
        return 'llama-3.3-70b-versatile';
    } else if (analysisType === 'deep' || documentSize >= 5000) {
        return 'mixtral-8x7b-32768';
    }
    return 'llama-3.3-70b-versatile'; // default
}
```

### ConfiguraciÃ³n Manual

Los usuarios pueden seleccionar manualmente:

1. **Tipo de AnÃ¡lisis**: RÃ¡pido, Balanceado, Profundo
2. **Modelo EspecÃ­fico**: Cualquier modelo disponible
3. **API Keys**: Configurar Groq y Chutes.ai

### Ejemplos de ConfiguraciÃ³n

#### Para AnÃ¡lisis RÃ¡pido
```javascript
{
    "useAI": true,
    "analysisType": "fast",
    "selectedModel": "llama-3.1-8b-instant"
}
```

#### Para AnÃ¡lisis Balanceado
```javascript
{
    "useAI": true,
    "analysisType": "balanced",
    "selectedModel": "llama-3.3-70b-versatile"
}
```

#### Para AnÃ¡lisis Profundo
```javascript
{
    "useAI": true,
    "analysisType": "deep",
    "selectedModel": "mixtral-8x7b-32768"
}
```

---

## ğŸš€ Mejores PrÃ¡cticas

### ğŸ“‹ Recomendaciones Generales

1. **Documentos PequeÃ±os (< 2 pÃ¡ginas)**
   - Usar `llama-3.1-8b-instant`
   - AnÃ¡lisis rÃ¡pido y eficiente

2. **Documentos Medianos (2-10 pÃ¡ginas)**
   - Usar `llama-3.3-70b-versatile`
   - Balance ideal calidad/velocidad

3. **Documentos Grandes (> 10 pÃ¡ginas)**
   - Usar `mixtral-8x7b-32768`
   - MÃ¡xima calidad para contenido complejo

4. **AnÃ¡lisis Especializado**
   - Considerar `chutes-specialized`
   - Para dominios especÃ­ficos

### âš¡ OptimizaciÃ³n de Rendimiento

#### DivisiÃ³n de Documentos
```javascript
// Para documentos muy largos, dividir en chunks
const chunks = splitDocumentIntoChunks(text, 8000);
const results = [];
for (const chunk of chunks) {
    const result = await analyzeChunk(chunk, model);
    results.push(result);
}
```

#### Caching de Resultados
```javascript
// Implementar cachÃ© para anÃ¡lisis repetidos
const cache = new Map();
function getCachedResult(hash) {
    return cache.get(hash);
}
function setCachedResult(hash, result) {
    cache.set(hash, result);
}
```

### ğŸ”§ ConfiguraciÃ³n de APIs

#### Groq API
```bash
# Configurar variable de entorno
export GROQ_API_KEY=gsk_your_api_key_here

# O en archivo .env
GROQ_API_KEY=gsk_your_api_key_here
```

#### Chutes.ai API
```bash
# Configurar variable de entorno
export CHUTES_API_KEY=your_chutes_key_here
export CHUTES_API_URL=https://api.chutes.ai
```

---

## ğŸ“ˆ MÃ©tricas y Monitoreo

### ğŸ“Š Indicadores Clave

#### Latencia
- **Ã“ptima**: < 200ms
- **Aceptable**: 200-500ms
- **Lenta**: > 500ms

#### PrecisiÃ³n
- **Excelente**: > 90%
- **Buena**: 80-90%
- **Aceptable**: 70-80%

#### Costo-Efectividad
- **Alta**: Llama 3.1 8B
- **Media**: Llama 3.3 70B
- **Baja**: Mixtral 8x7B

### ğŸ“± Monitoreo en Tiempo Real

La aplicaciÃ³n proporciona monitoreo de:
- Estado de APIs
- Tiempos de procesamiento
- Costos acumulados
- Calidad de resultados

---

## ğŸ”® Futuro de los Modelos

### ğŸš€ PrÃ³ximas Integraciones

1. **Modelos Multimodales**: AnÃ¡lisis de imÃ¡genes y texto
2. **Modelos Especializados**: Fine-tuning para dominios especÃ­ficos
3. **Modelos Locales**: Opciones on-premise para privacidad
4. **Modelos Personalizados**: Entrenamiento con datos del usuario

### ğŸ“ˆ Roadmap

- **Q1 2024**: IntegraciÃ³n con mÃ¡s proveedores de IA
- **Q2 2024**: Modelos multimodales
- **Q3 2024**: Fine-tuning personalizado
- **Q4 2024**: Modelos locales y edge computing

---

## ğŸ†˜ Soporte y Troubleshooting

### âŒ Problemas Comunes

#### Error: "Invalid API Key"
- **SoluciÃ³n**: Verificar la API key en la configuraciÃ³n
- **Causa**: API key incorrecta o expirada

#### Error: "Model not found"
- **SoluciÃ³n**: Verificar el ID del modelo
- **Causa**: Modelo no disponible o nombre incorrecto

#### Error: "Context length exceeded"
- **SoluciÃ³n**: Usar modelo con mayor ventana de contexto
- **Causa**: Documento muy largo para el modelo seleccionado

#### Error: "Rate limit exceeded"
- **SoluciÃ³n**: Esperar y reintentar, o usar plan superior
- **Causa**: LÃ­mite de peticiones por minuto excedido

### ğŸ“ Obtener Ayuda

1. **DocumentaciÃ³n**: Revisar guÃ­as detalladas
2. **Logs**: Verificar logs del servidor
3. **Estado**: Verificar estado de APIs en `/api/ai-status`
4. **Soporte**: Contactar al equipo de desarrollo

---

**Ãšltima actualizaciÃ³n**: Diciembre 2024  
**VersiÃ³n**: 1.0.0  
**Compatibilidad**: Node.js 14+, Navegadores modernos